# Final project
### *ITMO / AI Talent Hub*

# Рекомендательная система докладов на конференции

* Репозиторий содержит реализацию **гибридной рекомендательной системы** для подбора схожих докладов на основе текстовых описаний с конференции.  
* Система использует **LLM-разметку от Mistral-large** как прокси-истину (ground truth) и дообученную модель **Sentence-BERT**, интегрированную с метаданными (категория, спикер, компания) через веса, оптимизированные с помощью **Optuna**. 

---
## Используемые технологии

- `sentence-transformers` (SBERT, BGE-M3)  
- `optuna` — байесовская оптимизация гиперпараметров  
- `mistralai` — генерация LLM-разметки  
- `scikit-learn`, `gensim`, `pandas`, `numpy`

## Требования и установка

1. Создайте файл `.env` в корне проекта и укажите ваш API-ключ Mistral:
```bash
   MISTRAL_API_KEY=your_mistral_api_key_here
```

2. Убедитесь, что у вас достаточно оперативной памяти (рекомендуется ≥8 ГБ).
Модель BAAI/bge-m3 требует ~5–6 ГБ VRAM/ОЗУ и может не запуститься в средах с ограничениями (например, Kaggle без GPU)

## Запуск

1. Генерация LLM-разметки
Если вы хотите перегенерировать или дополнить кэш схожести:
```bash
    python mark.py
```

`Скрипт сохраняет прогресс в similarity_cache.json после каждого вызова API.
При повторном запуске будут обработаны только новые пары.`

2. Запуск экспериментов
Откройте notebook.ipynb в Jupyter / Colab / VS Code и выполните ячейки последовательно.

Основные этапы:

- Предобработка данных (preprocess_data)
- Векторизация текстов: TF-IDF, Word2Vec, SBERT, BGE-M3
- Оценка бейзлайнов по двум протоколам:
- Relevance@5 — совпадение категории
- Recall@5 — совпадение с LLM-GT (порог ≥0.5)
- Гибридизация + оптимизация весов через Optuna
- Fine-tuning SBERT на soft-labels от LLM
- Финальная оценка: Composite Score = 0.601

## Ключевые особенности реализации

- LLM-as-annotator: все 2850 пар докладов оценены Mistral-large по шкале [0.0, 1.0].
- Fine-tuning на регрессию: используется MSE-потеря на нормализованном косинусном сходстве.
- Гибридный скор:
```bash
    score = w_sem * sim_emb + w_cat * I[cat_match] + ...
```

- Composite Score: линейная комбинация 0.7 * Relevance/Recall + 0.3 * Diversity.
- Ограничение BGE-M3: из-за высоких требований к памяти файнтюнинг проводился только на SBERT.

## Результаты

| Модель                | Recall@5 | Diversity | Composite |
|----------------------|-------------|-----------|-----------|
| TF-IDF               | 0.208       | 0.958     | 0.433     |
| Word2Vec             | 0.048       | 0.108     | 0.066     |
|BM25             | 0.109 |     0.960   |   0.365 |
| Sentence-BERT        | 0.256       | 0.511     | 0.333     |
| BGE-M3 | 0.281 | 0.459 | 0.335 |
| Hybrid (BGE + Optuna) | 0.361 | 0.469 | 0.394 |
| Hybrid (SBERT + Optuna) | 0.329 | 0.533 | 0.390 |
| SBERT (Fine-tuned on LLM-GT) | 0.373 | 0.846 | 0.515 |
| **Hybrid (Fine-tuned SBERT + Optuna)** | **0.487** | **0.867** | **0.601** |
| LLM Oracle | 1.000 | 0.499 | 0.850 |
