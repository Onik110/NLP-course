{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e60575-3104-4ee0-8f0e-85648721034a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:23.677056Z",
     "iopub.status.busy": "2026-01-16T18:27:23.676770Z",
     "iopub.status.idle": "2026-01-16T18:27:26.682000Z",
     "shell.execute_reply": "2026-01-16T18:27:26.681351Z",
     "shell.execute_reply.started": "2026-01-16T18:27:23.677009Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank-bm25) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install rank-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd09577-8132-4d12-832f-aadf6eed30c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:26.684115Z",
     "iopub.status.busy": "2026-01-16T18:27:26.683288Z",
     "iopub.status.idle": "2026-01-16T18:27:44.070753Z",
     "shell.execute_reply": "2026-01-16T18:27:44.070190Z",
     "shell.execute_reply.started": "2026-01-16T18:27:26.684068Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1729/1387270424.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "2026-01-16 18:27:39.971663: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768588059.993423    1729 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768588059.999887    1729 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768588060.016959    1729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768588060.016976    1729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768588060.016979    1729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768588060.016981    1729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import optuna\n",
    "from rank_bm25 import BM25Okapi\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "244f411a-c7f3-44b6-99c2-d536a9e9f354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.073453Z",
     "iopub.status.busy": "2026-01-16T18:27:44.072851Z",
     "iopub.status.idle": "2026-01-16T18:27:44.077436Z",
     "shell.execute_reply": "2026-01-16T18:27:44.076681Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.073427Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = re.sub(r\"[\\r\\n]+\", \" \", str(text))\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a22ae6c-682c-438f-ac69-9570b8e07a40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.078667Z",
     "iopub.status.busy": "2026-01-16T18:27:44.078340Z",
     "iopub.status.idle": "2026-01-16T18:27:44.091420Z",
     "shell.execute_reply": "2026-01-16T18:27:44.090909Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.078639Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df, min_category_size=3):\n",
    "    df = df.copy()\n",
    "    missing_idx_map = {\n",
    "        0: \"Interesting things\",\n",
    "        39: \"General\",\n",
    "        40: \"Interesting things\",\n",
    "        56: \"Interesting things\",\n",
    "        74: \"General\",\n",
    "        75: \"Interesting things\"\n",
    "    }\n",
    "    for idx, cat in missing_idx_map.items():\n",
    "        if idx in df.index and pd.isna(df.loc[idx, 'category']):\n",
    "            df.loc[idx, 'category'] = cat\n",
    "\n",
    "    df[\"title\"] = df[\"title\"].apply(clean_text)\n",
    "    df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "    df[\"content\"] = df[\"title\"] + \" \" + df[\"text\"]\n",
    "\n",
    "    category_counts = df[\"category\"].value_counts()\n",
    "    valid_cats = category_counts[category_counts >= min_category_size].index\n",
    "    df = df[df[\"category\"].isin(valid_cats)].reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d1ed878-22da-4f39-845b-7800f105b6f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.092487Z",
     "iopub.status.busy": "2026-01-16T18:27:44.092212Z",
     "iopub.status.idle": "2026-01-16T18:27:44.103645Z",
     "shell.execute_reply": "2026-01-16T18:27:44.102954Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.092458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fdaccd4-9d79-48f4-ae72-be7ea01fb435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.104829Z",
     "iopub.status.busy": "2026-01-16T18:27:44.104571Z",
     "iopub.status.idle": "2026-01-16T18:27:44.113878Z",
     "shell.execute_reply": "2026-01-16T18:27:44.113261Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.104800Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_w2v_doc_vector(tokens, model):\n",
    "    vecs = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(vecs, axis=0) if vecs else np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5b93f30-418f-4804-9dd0-c22892f8a7c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.114912Z",
     "iopub.status.busy": "2026-01-16T18:27:44.114642Z",
     "iopub.status.idle": "2026-01-16T18:27:44.130747Z",
     "shell.execute_reply": "2026-01-16T18:27:44.130074Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.114890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def vectorize_texts(docs, models_to_use=[\"sbert\", \"tfidf\", \"w2v\", \"bge\"]):\n",
    "    embeddings = {}\n",
    "    if \"sbert\" in models_to_use:\n",
    "        sbert_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "        embeddings[\"sbert\"] = sbert_model.encode(docs, show_progress_bar=False)\n",
    "\n",
    "    if \"tfidf\" in models_to_use:\n",
    "        tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "        embeddings[\"tfidf\"] = tfidf.fit_transform(docs).toarray()\n",
    "\n",
    "    if \"w2v\" in models_to_use:\n",
    "        tokenized_docs = [tokenize(doc) for doc in docs]\n",
    "        w2v_model = Word2Vec(tokenized_docs, vector_size=100, window=5, min_count=1, seed=42, workers=1)\n",
    "        w2v_embeddings = np.array([\n",
    "            get_w2v_doc_vector(tokens, w2v_model) for tokens in tokenized_docs\n",
    "        ])\n",
    "        embeddings[\"w2v\"] = w2v_embeddings\n",
    "\n",
    "    if \"bge\" in models_to_use:\n",
    "        bge_model = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "        embeddings[\"bge\"] = bge_model.encode(docs, normalize_embeddings=True, show_progress_bar=False)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dbb66fd-76bb-4b20-8632-5295c41c0563",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.131718Z",
     "iopub.status.busy": "2026-01-16T18:27:44.131537Z",
     "iopub.status.idle": "2026-01-16T18:27:44.140722Z",
     "shell.execute_reply": "2026-01-16T18:27:44.140150Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.131699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def hybrid_recommend(query_idx, df, embeddings, w_sem=0.7, w_cat=0.3, w_speaker=0.0, w_companies=0.0, top_k=5):\n",
    "    n = len(df)\n",
    "    scores = np.zeros(n)\n",
    "    query_emb = embeddings[query_idx]\n",
    "    query_cat = df.iloc[query_idx][\"category\"]\n",
    "    query_speaker = df.iloc[query_idx][\"speaker\"]\n",
    "    query_companies = df.iloc[query_idx][\"companies\"]\n",
    "\n",
    "    for i in range(n):\n",
    "        if i == query_idx:\n",
    "            continue\n",
    "        sem_sim = cosine_similarity([query_emb], [embeddings[i]])[0][0]\n",
    "        cat_match = float(df.iloc[i][\"category\"] == query_cat)\n",
    "        speaker_match = float(df.iloc[i][\"speaker\"] == query_speaker)\n",
    "        companies_match = float(df.iloc[i][\"companies\"] == query_companies)\n",
    "        scores[i] = (\n",
    "            w_sem * sem_sim +\n",
    "            w_cat * cat_match +\n",
    "            w_speaker * speaker_match +\n",
    "            w_companies * companies_match\n",
    "        )\n",
    "\n",
    "    top_idxs = np.argsort(-scores)[:top_k + 1]\n",
    "    return [i for i in top_idxs if i != query_idx][:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b137ba0d-0588-451e-80cb-8e56f06e7d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.141626Z",
     "iopub.status.busy": "2026-01-16T18:27:44.141396Z",
     "iopub.status.idle": "2026-01-16T18:27:44.153522Z",
     "shell.execute_reply": "2026-01-16T18:27:44.152904Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.141595Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def recommend_by_similarity(query_idx, embeddings, top_k=5):\n",
    "    sims = cosine_similarity([embeddings[query_idx]], embeddings).flatten()\n",
    "    sims[query_idx] = -1\n",
    "    top_idxs = np.argsort(-sims)[:top_k]\n",
    "    return top_idxs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a63bae55-e7bc-4e4c-bc8b-91b30b045824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.154779Z",
     "iopub.status.busy": "2026-01-16T18:27:44.154331Z",
     "iopub.status.idle": "2026-01-16T18:27:44.167567Z",
     "shell.execute_reply": "2026-01-16T18:27:44.167078Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.154755Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def recommend_by_bm25(query_idx, docs, top_k=5):\n",
    "    tokenized_docs = [doc.lower().split() for doc in docs]\n",
    "    bm25 = BM25Okapi(tokenized_docs)\n",
    "    query_tokens = tokenized_docs[query_idx]\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "    scores[query_idx] = -np.inf\n",
    "    top_idxs = np.argsort(-scores)[:top_k]\n",
    "    return top_idxs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd6ecda1-80d7-4226-a975-6c9b0bea6f43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.168907Z",
     "iopub.status.busy": "2026-01-16T18:27:44.168608Z",
     "iopub.status.idle": "2026-01-16T18:27:44.178056Z",
     "shell.execute_reply": "2026-01-16T18:27:44.177522Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.168885Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_llm_cache(cache_path):\n",
    "    with open(cache_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c8b62b5-d785-40fa-a5a6-ed5a7e038cef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.179651Z",
     "iopub.status.busy": "2026-01-16T18:27:44.178940Z",
     "iopub.status.idle": "2026-01-16T18:27:44.190260Z",
     "shell.execute_reply": "2026-01-16T18:27:44.189581Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.179627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_llm_ground_truth_for_talk(query_talk_id, df, cache, min_score=0.5):\n",
    "    relevant_talks = []\n",
    "    for _, row in df.iterrows():\n",
    "        other_id = row[\"talk_id\"]\n",
    "        if other_id == query_talk_id:\n",
    "            continue\n",
    "        key = f\"{min(query_talk_id, other_id)}_{max(query_talk_id, other_id)}\"\n",
    "        score = cache.get(key, 0.0)\n",
    "        if score >= min_score:\n",
    "            relevant_talks.append((other_id, score))\n",
    "    relevant_talks.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [tid for tid, _ in relevant_talks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fe610c7-0863-4f4c-9aa8-a27e331391df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.191588Z",
     "iopub.status.busy": "2026-01-16T18:27:44.191235Z",
     "iopub.status.idle": "2026-01-16T18:27:44.203091Z",
     "shell.execute_reply": "2026-01-16T18:27:44.202393Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.191557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def llm_rerank_recommend(query_idx, df, cache, top_k=5):\n",
    "    query_talk_id = df.iloc[query_idx][\"talk_id\"]\n",
    "    scores = []\n",
    "    for idx, row in df.iterrows():\n",
    "        if idx == query_idx:\n",
    "            continue\n",
    "        other_talk_id = row[\"talk_id\"]\n",
    "        key = f\"{min(query_talk_id, other_talk_id)}_{max(query_talk_id, other_talk_id)}\"\n",
    "        llm_score = cache.get(key, 0.0)\n",
    "        scores.append((idx, llm_score))\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [idx for idx, _ in scores[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea1912fd-3619-44a2-af4d-c5489b815b46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.204083Z",
     "iopub.status.busy": "2026-01-16T18:27:44.203817Z",
     "iopub.status.idle": "2026-01-16T18:27:44.215186Z",
     "shell.execute_reply": "2026-01-16T18:27:44.214623Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.204047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model_name,\n",
    "    recommend_fn,\n",
    "    df,\n",
    "    embeddings_for_diversity,\n",
    "    gt_type=\"category\",\n",
    "    cache=None,\n",
    "    min_score=0.5,\n",
    "    top_k=5\n",
    "):\n",
    "    relevance_scores = []\n",
    "    diversity_scores = []\n",
    "\n",
    "    for idx in range(len(df)):\n",
    "        try:\n",
    "            recs = recommend_fn(idx)\n",
    "            if not recs:\n",
    "                continue\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # Relevance \n",
    "        if gt_type == \"category\":\n",
    "            query_cat = df.iloc[idx][\"category\"]\n",
    "            relevance = sum(1 for i in recs if df.iloc[i][\"category\"] == query_cat) / len(recs)\n",
    "        elif gt_type == \"llm\":\n",
    "            if cache is None:\n",
    "                continue\n",
    "            query_talk_id = df.iloc[idx][\"talk_id\"]\n",
    "            llm_gt = get_llm_ground_truth_for_talk(query_talk_id, df, cache, min_score=min_score)\n",
    "            if not llm_gt:\n",
    "                continue\n",
    "            rec_talk_ids = [df.iloc[i][\"talk_id\"] for i in recs[:top_k]]\n",
    "            recall = len(set(llm_gt) & set(rec_talk_ids)) / len(llm_gt)\n",
    "            relevance = recall\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Diversity (по эмбеддингам)\n",
    "        if len(recs) == 1:\n",
    "            diversity = 1.0\n",
    "        else:\n",
    "            valid_embs = []\n",
    "            for i in recs:\n",
    "                if i < len(embeddings_for_diversity):\n",
    "                    valid_embs.append(embeddings_for_diversity[i])\n",
    "            if len(valid_embs) < 2:\n",
    "                diversity = 1.0\n",
    "            else:\n",
    "                rec_embs = np.array(valid_embs)\n",
    "                sim_mat = cosine_similarity(rec_embs)\n",
    "                np.fill_diagonal(sim_mat, 0)\n",
    "                avg_sim = sim_mat.sum() / (len(rec_embs) * (len(rec_embs) - 1))\n",
    "                diversity = 1.0 - avg_sim\n",
    "\n",
    "        relevance_scores.append(relevance)\n",
    "        diversity_scores.append(diversity)\n",
    "\n",
    "    avg_rel = np.mean(relevance_scores) if relevance_scores else 0.0\n",
    "    avg_div = np.mean(diversity_scores) if diversity_scores else 0.0\n",
    "    composite = 0.7 * avg_rel + 0.3 * avg_div\n",
    "\n",
    "    metric_name = \"Relevance@5\" if gt_type == \"category\" else f\"Recall@{top_k} (LLM-GT)\"\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        metric_name: round(avg_rel, 3),\n",
    "        \"Diversity\": round(avg_div, 3),\n",
    "        \"Composite\": round(composite, 3)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec680f29-5582-4e61-a657-9143b0bb48d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.216213Z",
     "iopub.status.busy": "2026-01-16T18:27:44.215928Z",
     "iopub.status.idle": "2026-01-16T18:27:44.230771Z",
     "shell.execute_reply": "2026-01-16T18:27:44.230081Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.216184Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def objective(trial, df, embeddings, gt_type=\"category\", cache=None, min_score=0.5):\n",
    "    w_sem = trial.suggest_float(\"w_sem\", 0.5, 1.0)\n",
    "    w_cat = trial.suggest_float(\"w_cat\", 0.0, 0.5)\n",
    "    w_speaker = trial.suggest_float(\"w_speaker\", 0.0, 0.3)\n",
    "    w_companies = trial.suggest_float(\"w_companies\", 0.0, 0.3)\n",
    "\n",
    "    composite_scores = []\n",
    "    for idx in range(len(df)):\n",
    "        recs = hybrid_recommend(idx, df, embeddings, w_sem, w_cat, w_speaker, w_companies, top_k=5)\n",
    "        if not recs:\n",
    "            continue\n",
    "\n",
    "        if gt_type == \"category\":\n",
    "            query_cat = df.iloc[idx][\"category\"]\n",
    "            relevance = sum(1 for i in recs if df.iloc[i][\"category\"] == query_cat) / len(recs)\n",
    "        elif gt_type == \"llm\":\n",
    "            if cache is None:\n",
    "                continue\n",
    "            query_talk_id = df.iloc[idx][\"talk_id\"]\n",
    "            llm_gt = get_llm_ground_truth_for_talk(query_talk_id, df, cache, min_score=min_score)\n",
    "            if not llm_gt:\n",
    "                continue\n",
    "            rec_talk_ids = [df.iloc[i][\"talk_id\"] for i in recs]\n",
    "            recall = len(set(llm_gt) & set(rec_talk_ids)) / len(llm_gt)\n",
    "            relevance = recall\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if len(recs) == 1:\n",
    "            diversity = 1.0\n",
    "        else:\n",
    "            rec_embs = embeddings[recs]\n",
    "            sim_mat = cosine_similarity(rec_embs)\n",
    "            np.fill_diagonal(sim_mat, 0)\n",
    "            avg_sim = sim_mat.sum() / (len(recs) * (len(recs) - 1))\n",
    "            diversity = 1.0 - avg_sim\n",
    "\n",
    "        composite = 0.7 * relevance + 0.3 * diversity\n",
    "        composite_scores.append(composite)\n",
    "\n",
    "    return np.mean(composite_scores) if composite_scores else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "004240ab-a07a-48a6-9309-b8507c08a29e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.232148Z",
     "iopub.status.busy": "2026-01-16T18:27:44.231630Z",
     "iopub.status.idle": "2026-01-16T18:27:44.246684Z",
     "shell.execute_reply": "2026-01-16T18:27:44.246042Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.232126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_optimization(df, embeddings, gt_type=\"category\", cache=None, n_trials=10, min_score=0.5):\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        sampler=optuna.samplers.TPESampler(seed=42)\n",
    "    )\n",
    "    study.optimize(\n",
    "        lambda trial: objective(trial, df, embeddings, gt_type, cache, min_score),\n",
    "        n_trials=n_trials,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "    return study.best_params, round(study.best_value, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e8f7a-ae11-4a9b-934f-9a9cd33bc8e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.250064Z",
     "iopub.status.busy": "2026-01-16T18:27:44.249780Z",
     "iopub.status.idle": "2026-01-16T18:27:44.307258Z",
     "shell.execute_reply": "2026-01-16T18:27:44.306523Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.250018Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv(\"dataset_jug.csv\")\n",
    "df = preprocess_data(df, min_category_size=3)\n",
    "df = df.reset_index(drop=True)\n",
    "df['talk_id'] = df.index\n",
    "docs = df[\"content\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e55c6806-358b-4751-af91-d794cea17e35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:44.308442Z",
     "iopub.status.busy": "2026-01-16T18:27:44.308164Z",
     "iopub.status.idle": "2026-01-16T18:27:55.140003Z",
     "shell.execute_reply": "2026-01-16T18:27:55.139402Z",
     "shell.execute_reply.started": "2026-01-16T18:27:44.308410Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Векторизация\n",
    "embeddings_dict = vectorize_texts(docs, models_to_use=[\"sbert\", \"tfidf\", \"w2v\", \"bge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d1a418-0404-485d-9a62-3b7306b39513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:55.141219Z",
     "iopub.status.busy": "2026-01-16T18:27:55.140892Z",
     "iopub.status.idle": "2026-01-16T18:27:55.147523Z",
     "shell.execute_reply": "2026-01-16T18:27:55.146849Z",
     "shell.execute_reply.started": "2026-01-16T18:27:55.141194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Загрузка LLM-кэша\n",
    "cache_path = \"similarity_cache.json\"\n",
    "llm_cache = load_llm_cache(cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6eca5dfa-cc98-4f1f-9755-57b8349ffb39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:27:55.148876Z",
     "iopub.status.busy": "2026-01-16T18:27:55.148518Z",
     "iopub.status.idle": "2026-01-16T18:28:27.216191Z",
     "shell.execute_reply": "2026-01-16T18:28:27.215449Z",
     "shell.execute_reply.started": "2026-01-16T18:27:55.148852Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка по совпадению категории (Relevance@5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-16 18:27:56,094]\u001b[0m A new study created in memory with name: no-name-6cbd6e09-4865-49a3-9d88-e277a966f1d7\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:27:58,934]\u001b[0m Trial 0 finished with value: 0.6882157325744629 and parameters: {'w_sem': 0.6872700594236812, 'w_cat': 0.4753571532049581, 'w_speaker': 0.21959818254342153, 'w_companies': 0.17959754525911098}. Best is trial 0 with value: 0.6882157325744629.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:01,727]\u001b[0m Trial 1 finished with value: 0.5956175923347473 and parameters: {'w_sem': 0.5780093202212182, 'w_cat': 0.07799726016810132, 'w_speaker': 0.017425083650459836, 'w_companies': 0.2598528437324805}. Best is trial 0 with value: 0.6882157325744629.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:04,547]\u001b[0m Trial 2 finished with value: 0.6861491799354553 and parameters: {'w_sem': 0.8005575058716043, 'w_cat': 0.35403628889802274, 'w_speaker': 0.006175348288740734, 'w_companies': 0.29097295564859826}. Best is trial 0 with value: 0.6882157325744629.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:07,326]\u001b[0m Trial 3 finished with value: 0.6202732920646667 and parameters: {'w_sem': 0.9162213204002109, 'w_cat': 0.10616955533913808, 'w_speaker': 0.05454749016213018, 'w_companies': 0.055021352956030146}. Best is trial 0 with value: 0.6882157325744629.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:10,156]\u001b[0m Trial 4 finished with value: 0.6883171200752258 and parameters: {'w_sem': 0.6521211214797689, 'w_cat': 0.2623782158161189, 'w_speaker': 0.12958350559263473, 'w_companies': 0.08736874205941257}. Best is trial 4 with value: 0.6883171200752258.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:13,046]\u001b[0m Trial 5 finished with value: 0.5618515610694885 and parameters: {'w_sem': 0.8059264473611898, 'w_cat': 0.06974693032602092, 'w_speaker': 0.08764339456056544, 'w_companies': 0.1099085529881075}. Best is trial 4 with value: 0.6883171200752258.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:15,894]\u001b[0m Trial 6 finished with value: 0.6882157325744629 and parameters: {'w_sem': 0.728034992108518, 'w_cat': 0.3925879806965068, 'w_speaker': 0.05990213464750792, 'w_companies': 0.15427033152408348}. Best is trial 4 with value: 0.6883171200752258.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:18,684]\u001b[0m Trial 7 finished with value: 0.38555896282196045 and parameters: {'w_sem': 0.7962072844310213, 'w_cat': 0.023225206359998862, 'w_speaker': 0.1822634555704315, 'w_companies': 0.051157237106187456}. Best is trial 4 with value: 0.6883171200752258.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:21,493]\u001b[0m Trial 8 finished with value: 0.6882157325744629 and parameters: {'w_sem': 0.5325257964926398, 'w_cat': 0.4744427686266666, 'w_speaker': 0.2896896099223678, 'w_companies': 0.24251920443493832}. Best is trial 4 with value: 0.6883171200752258.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:24,310]\u001b[0m Trial 9 finished with value: 0.5235317945480347 and parameters: {'w_sem': 0.6523068845866853, 'w_cat': 0.048836057003191935, 'w_speaker': 0.20526990795364705, 'w_companies': 0.13204574812188039}. Best is trial 4 with value: 0.6883171200752258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model  Relevance@5  Diversity  Composite\n",
      "               TF-IDF        0.169      0.957      0.405\n",
      "             Word2Vec        0.097      0.106      0.100\n",
      "        Sentence-BERT        0.186      0.509      0.283\n",
      "               BGE-M3        0.206      0.463      0.283\n",
      "                 BM25        0.123      0.959      0.374\n",
      "Hybrid (BGE + Optuna)        0.777      0.481      0.688\n"
     ]
    }
   ],
   "source": [
    "print(\"Оценка по совпадению категории (Relevance@5)\")\n",
    "\n",
    "results_category = []\n",
    "\n",
    "# Dense и sparse модели\n",
    "for name, emb_key in [(\"TF-IDF\", \"tfidf\"), (\"Word2Vec\", \"w2v\"), (\"Sentence-BERT\", \"sbert\"), (\"BGE-M3\", \"bge\")]:\n",
    "    if emb_key in embeddings_dict:\n",
    "        results_category.append(\n",
    "            evaluate_model(\n",
    "                model_name=name,\n",
    "                recommend_fn=lambda idx, key=emb_key: recommend_by_similarity(idx, embeddings_dict[key]),\n",
    "                df=df,\n",
    "                embeddings_for_diversity=embeddings_dict[emb_key],\n",
    "                gt_type=\"category\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "# BM25\n",
    "results_category.append(\n",
    "    evaluate_model(\n",
    "        model_name=\"BM25\",\n",
    "        recommend_fn=lambda idx: recommend_by_bm25(idx, docs),\n",
    "        df=df,\n",
    "        embeddings_for_diversity=embeddings_dict[\"tfidf\"],\n",
    "        gt_type=\"category\"\n",
    "    )\n",
    ")\n",
    "\n",
    "best_weights_cat, _ = run_optimization(df, embeddings_dict[\"bge\"], gt_type=\"category\", n_trials=10)\n",
    "results_category.append(\n",
    "    evaluate_model(\n",
    "        model_name=\"Hybrid (BGE + Optuna)\",\n",
    "        recommend_fn=lambda idx: hybrid_recommend(idx, df, embeddings_dict[\"bge\"], **best_weights_cat),\n",
    "        df=df,\n",
    "        embeddings_for_diversity=embeddings_dict[\"bge\"],\n",
    "        gt_type=\"category\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(pd.DataFrame(results_category).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a3a750c-6164-4367-a51e-eb1198a34685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:28:27.217394Z",
     "iopub.status.busy": "2026-01-16T18:28:27.217087Z",
     "iopub.status.idle": "2026-01-16T18:30:35.519515Z",
     "shell.execute_reply": "2026-01-16T18:30:35.518827Z",
     "shell.execute_reply.started": "2026-01-16T18:28:27.217367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка по LLM-based ground truth (Recall@5, min_score=0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-16 18:28:28,986]\u001b[0m A new study created in memory with name: no-name-9d5e45fa-d463-4db0-a030-98659e0e595b\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:32,068]\u001b[0m Trial 0 finished with value: 0.31171026825904846 and parameters: {'w_sem': 0.6872700594236812, 'w_cat': 0.4753571532049581, 'w_speaker': 0.21959818254342153, 'w_companies': 0.17959754525911098}. Best is trial 0 with value: 0.31171026825904846.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:35,159]\u001b[0m Trial 1 finished with value: 0.3192254304885864 and parameters: {'w_sem': 0.5780093202212182, 'w_cat': 0.07799726016810132, 'w_speaker': 0.017425083650459836, 'w_companies': 0.2598528437324805}. Best is trial 1 with value: 0.3192254304885864.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:38,122]\u001b[0m Trial 2 finished with value: 0.31171026825904846 and parameters: {'w_sem': 0.8005575058716043, 'w_cat': 0.35403628889802274, 'w_speaker': 0.006175348288740734, 'w_companies': 0.29097295564859826}. Best is trial 1 with value: 0.3192254304885864.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:41,136]\u001b[0m Trial 3 finished with value: 0.37229862809181213 and parameters: {'w_sem': 0.9162213204002109, 'w_cat': 0.10616955533913808, 'w_speaker': 0.05454749016213018, 'w_companies': 0.055021352956030146}. Best is trial 3 with value: 0.37229862809181213.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:44,152]\u001b[0m Trial 4 finished with value: 0.31171026825904846 and parameters: {'w_sem': 0.6521211214797689, 'w_cat': 0.2623782158161189, 'w_speaker': 0.12958350559263473, 'w_companies': 0.08736874205941257}. Best is trial 3 with value: 0.37229862809181213.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:47,133]\u001b[0m Trial 5 finished with value: 0.3793741464614868 and parameters: {'w_sem': 0.8059264473611898, 'w_cat': 0.06974693032602092, 'w_speaker': 0.08764339456056544, 'w_companies': 0.1099085529881075}. Best is trial 5 with value: 0.3793741464614868.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:50,117]\u001b[0m Trial 6 finished with value: 0.31171026825904846 and parameters: {'w_sem': 0.728034992108518, 'w_cat': 0.3925879806965068, 'w_speaker': 0.05990213464750792, 'w_companies': 0.15427033152408348}. Best is trial 5 with value: 0.3793741464614868.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:53,116]\u001b[0m Trial 7 finished with value: 0.3685244023799896 and parameters: {'w_sem': 0.7962072844310213, 'w_cat': 0.023225206359998862, 'w_speaker': 0.1822634555704315, 'w_companies': 0.051157237106187456}. Best is trial 5 with value: 0.3793741464614868.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:56,091]\u001b[0m Trial 8 finished with value: 0.31171026825904846 and parameters: {'w_sem': 0.5325257964926398, 'w_cat': 0.4744427686266666, 'w_speaker': 0.2896896099223678, 'w_companies': 0.24251920443493832}. Best is trial 5 with value: 0.3793741464614868.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:28:59,064]\u001b[0m Trial 9 finished with value: 0.352764755487442 and parameters: {'w_sem': 0.6523068845866853, 'w_cat': 0.048836057003191935, 'w_speaker': 0.20526990795364705, 'w_companies': 0.13204574812188039}. Best is trial 5 with value: 0.3793741464614868.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:02,082]\u001b[0m Trial 10 finished with value: 0.3215777277946472 and parameters: {'w_sem': 0.97784393019022, 'w_cat': 0.18186383681081547, 'w_speaker': 0.11176130617270665, 'w_companies': 0.005388562684445819}. Best is trial 5 with value: 0.3793741464614868.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:05,102]\u001b[0m Trial 11 finished with value: 0.3553397059440613 and parameters: {'w_sem': 0.9107426358313142, 'w_cat': 0.15028241152467287, 'w_speaker': 0.07663303762955956, 'w_companies': 0.08403190349838605}. Best is trial 5 with value: 0.3793741464614868.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:08,038]\u001b[0m Trial 12 finished with value: 0.3543241024017334 and parameters: {'w_sem': 0.8723304497253677, 'w_cat': 0.13872436111594902, 'w_speaker': 0.06470640421231977, 'w_companies': 0.002712244523209839}. Best is trial 5 with value: 0.3793741464614868.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:10,975]\u001b[0m Trial 13 finished with value: 0.31171080470085144 and parameters: {'w_sem': 0.8732737430254675, 'w_cat': 0.22811599320828918, 'w_speaker': 0.1027547981213269, 'w_companies': 0.09731311377947177}. Best is trial 5 with value: 0.3793741464614868.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:13,932]\u001b[0m Trial 14 finished with value: 0.39375460147857666 and parameters: {'w_sem': 0.9864019903245632, 'w_cat': 0.1020423090859486, 'w_speaker': 0.043004834784990696, 'w_companies': 0.0440841556830138}. Best is trial 14 with value: 0.39375460147857666.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:16,913]\u001b[0m Trial 15 finished with value: 0.3299974799156189 and parameters: {'w_sem': 0.9700231951448373, 'w_cat': 0.007391238520434218, 'w_speaker': 0.14500333003969673, 'w_companies': 0.1958043600674942}. Best is trial 14 with value: 0.39375460147857666.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:19,887]\u001b[0m Trial 16 finished with value: 0.3110602796077728 and parameters: {'w_sem': 0.8138214726279749, 'w_cat': 0.22260436479670398, 'w_speaker': 0.02406321803951139, 'w_companies': 0.03734748458022765}. Best is trial 14 with value: 0.39375460147857666.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:22,919]\u001b[0m Trial 17 finished with value: 0.31171026825904846 and parameters: {'w_sem': 0.9931754437804192, 'w_cat': 0.2893216394980081, 'w_speaker': 0.09634555872121228, 'w_companies': 0.12430151041770698}. Best is trial 14 with value: 0.39375460147857666.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:25,876]\u001b[0m Trial 18 finished with value: 0.35559165477752686 and parameters: {'w_sem': 0.7484483315394532, 'w_cat': 0.10770962563725192, 'w_speaker': 0.16634371231158904, 'w_companies': 0.11773992572003279}. Best is trial 14 with value: 0.39375460147857666.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:28,867]\u001b[0m Trial 19 finished with value: 0.3527695834636688 and parameters: {'w_sem': 0.8416220299255135, 'w_cat': 0.06252162457078848, 'w_speaker': 0.036212639933367714, 'w_companies': 0.16625802669133327}. Best is trial 14 with value: 0.39375460147857666.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:31,954]\u001b[0m A new study created in memory with name: no-name-2cb8933e-3364-4f80-a6ef-e19839fe25a3\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:35,018]\u001b[0m Trial 0 finished with value: 0.3359507918357849 and parameters: {'w_sem': 0.6872700594236812, 'w_cat': 0.4753571532049581, 'w_speaker': 0.21959818254342153, 'w_companies': 0.17959754525911098}. Best is trial 0 with value: 0.3359507918357849.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:38,112]\u001b[0m Trial 1 finished with value: 0.3545456528663635 and parameters: {'w_sem': 0.5780093202212182, 'w_cat': 0.07799726016810132, 'w_speaker': 0.017425083650459836, 'w_companies': 0.2598528437324805}. Best is trial 1 with value: 0.3545456528663635.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:41,028]\u001b[0m Trial 2 finished with value: 0.3360971212387085 and parameters: {'w_sem': 0.8005575058716043, 'w_cat': 0.35403628889802274, 'w_speaker': 0.006175348288740734, 'w_companies': 0.29097295564859826}. Best is trial 1 with value: 0.3545456528663635.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:44,043]\u001b[0m Trial 3 finished with value: 0.3904084265232086 and parameters: {'w_sem': 0.9162213204002109, 'w_cat': 0.10616955533913808, 'w_speaker': 0.05454749016213018, 'w_companies': 0.055021352956030146}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:47,028]\u001b[0m Trial 4 finished with value: 0.33444449305534363 and parameters: {'w_sem': 0.6521211214797689, 'w_cat': 0.2623782158161189, 'w_speaker': 0.12958350559263473, 'w_companies': 0.08736874205941257}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:50,038]\u001b[0m Trial 5 finished with value: 0.35999107360839844 and parameters: {'w_sem': 0.8059264473611898, 'w_cat': 0.06974693032602092, 'w_speaker': 0.08764339456056544, 'w_companies': 0.1099085529881075}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:53,053]\u001b[0m Trial 6 finished with value: 0.33545589447021484 and parameters: {'w_sem': 0.728034992108518, 'w_cat': 0.3925879806965068, 'w_speaker': 0.05990213464750792, 'w_companies': 0.15427033152408348}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:56,046]\u001b[0m Trial 7 finished with value: 0.34085625410079956 and parameters: {'w_sem': 0.7962072844310213, 'w_cat': 0.023225206359998862, 'w_speaker': 0.1822634555704315, 'w_companies': 0.051157237106187456}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:29:59,172]\u001b[0m Trial 8 finished with value: 0.3359507918357849 and parameters: {'w_sem': 0.5325257964926398, 'w_cat': 0.4744427686266666, 'w_speaker': 0.2896896099223678, 'w_companies': 0.24251920443493832}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:30:02,126]\u001b[0m Trial 9 finished with value: 0.35534733533859253 and parameters: {'w_sem': 0.6523068845866853, 'w_cat': 0.048836057003191935, 'w_speaker': 0.20526990795364705, 'w_companies': 0.13204574812188039}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:30:05,105]\u001b[0m Trial 10 finished with value: 0.3621847629547119 and parameters: {'w_sem': 0.9725682721151934, 'w_cat': 0.18186383681081547, 'w_speaker': 0.11061863181632911, 'w_companies': 0.005388562684445819}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:30:08,041]\u001b[0m Trial 11 finished with value: 0.3620876669883728 and parameters: {'w_sem': 0.9799381125424057, 'w_cat': 0.17193377205650728, 'w_speaker': 0.10912464381815776, 'w_companies': 0.0036231835506683116}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:30:10,988]\u001b[0m Trial 12 finished with value: 0.36417460441589355 and parameters: {'w_sem': 0.9841385767965631, 'w_cat': 0.18980212171011157, 'w_speaker': 0.05866139459648484, 'w_companies': 0.00286441846520904}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:30:13,973]\u001b[0m Trial 13 finished with value: 0.36303403973579407 and parameters: {'w_sem': 0.8991358530198216, 'w_cat': 0.16050470383714383, 'w_speaker': 0.054685757239448525, 'w_companies': 0.055741619202817415}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:30:16,969]\u001b[0m Trial 14 finished with value: 0.3604639172554016 and parameters: {'w_sem': 0.9107299769973456, 'w_cat': 0.2485737903283322, 'w_speaker': 0.05315760075891079, 'w_companies': 0.04950177067684451}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:30:20,007]\u001b[0m Trial 15 finished with value: 0.3704689145088196 and parameters: {'w_sem': 0.8956081614263436, 'w_cat': 0.120403968750455, 'w_speaker': 0.15531401032512526, 'w_companies': 0.025910676545781122}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:30:23,142]\u001b[0m Trial 16 finished with value: 0.38080674409866333 and parameters: {'w_sem': 0.8859620061900355, 'w_cat': 0.11367926852636352, 'w_speaker': 0.16675005394706932, 'w_companies': 0.19343836080210308}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:30:26,148]\u001b[0m Trial 17 finished with value: 0.3320663571357727 and parameters: {'w_sem': 0.864651249295386, 'w_cat': 0.0017684718609611016, 'w_speaker': 0.25911944644397994, 'w_companies': 0.19335543462846938}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:30:29,122]\u001b[0m Trial 18 finished with value: 0.36116498708724976 and parameters: {'w_sem': 0.8380572523758589, 'w_cat': 0.12077746649016971, 'w_speaker': 0.1517051024912028, 'w_companies': 0.21104927297179268}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:30:32,149]\u001b[0m Trial 19 finished with value: 0.3597884476184845 and parameters: {'w_sem': 0.9350746750008209, 'w_cat': 0.23348090644524588, 'w_speaker': 0.19085188598525574, 'w_companies': 0.14357812053647975}. Best is trial 3 with value: 0.3904084265232086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Model  Recall@5 (LLM-GT)  Diversity  Composite\n",
      "                 TF-IDF              0.208      0.958      0.433\n",
      "               Word2Vec              0.048      0.108      0.066\n",
      "          Sentence-BERT              0.256      0.511      0.333\n",
      "                 BGE-M3              0.281      0.459      0.335\n",
      "                   BM25              0.109      0.960      0.365\n",
      "  Hybrid (BGE + Optuna)              0.361      0.469      0.394\n",
      "Hybrid (SBERT + Optuna)              0.329      0.533      0.390\n",
      "  LLM Oracle (Reranked)              1.000      0.499      0.850\n"
     ]
    }
   ],
   "source": [
    "print(\"Оценка по LLM-based ground truth (Recall@5, min_score=0.5)\")\n",
    "\n",
    "results_llm = []\n",
    "\n",
    "# Dense и sparse модели\n",
    "for name, emb_key in [(\"TF-IDF\", \"tfidf\"), (\"Word2Vec\", \"w2v\"), (\"Sentence-BERT\", \"sbert\"), (\"BGE-M3\", \"bge\")]:\n",
    "    if emb_key in embeddings_dict:\n",
    "        results_llm.append(\n",
    "            evaluate_model(\n",
    "                model_name=name,\n",
    "                recommend_fn=lambda idx, key=emb_key: recommend_by_similarity(idx, embeddings_dict[key]),\n",
    "                df=df,\n",
    "                embeddings_for_diversity=embeddings_dict[emb_key],\n",
    "                gt_type=\"llm\",\n",
    "                cache=llm_cache,\n",
    "                min_score=0.5\n",
    "            )\n",
    "        )\n",
    "\n",
    "# BM25\n",
    "results_llm.append(\n",
    "    evaluate_model(\n",
    "        model_name=\"BM25\",\n",
    "        recommend_fn=lambda idx: recommend_by_bm25(idx, docs),\n",
    "        df=df,\n",
    "        embeddings_for_diversity=embeddings_dict[\"tfidf\"],\n",
    "        gt_type=\"llm\",\n",
    "        cache=llm_cache,\n",
    "        min_score=0.5\n",
    "    )\n",
    ")\n",
    "\n",
    "# Hybrid (BGE + Optuna)\n",
    "best_weights_llm_bge, _ = run_optimization(\n",
    "    df, embeddings_dict[\"bge\"], gt_type=\"llm\", cache=llm_cache, n_trials=20, min_score=0.5\n",
    ")\n",
    "results_llm.append(\n",
    "    evaluate_model(\n",
    "        model_name=\"Hybrid (BGE + Optuna)\",\n",
    "        recommend_fn=lambda idx: hybrid_recommend(idx, df, embeddings_dict[\"bge\"], **best_weights_llm_bge),\n",
    "        df=df,\n",
    "        embeddings_for_diversity=embeddings_dict[\"bge\"],\n",
    "        gt_type=\"llm\",\n",
    "        cache=llm_cache,\n",
    "        min_score=0.5\n",
    "    )\n",
    ")\n",
    "\n",
    "# Hybrid (SBERT + Optuna)\n",
    "best_weights_llm_sbert_base, _ = run_optimization(\n",
    "    df, embeddings_dict[\"sbert\"], gt_type=\"llm\", cache=llm_cache, n_trials=20, min_score=0.5\n",
    ")\n",
    "results_llm.append(\n",
    "    evaluate_model(\n",
    "        model_name=\"Hybrid (SBERT + Optuna)\",\n",
    "        recommend_fn=lambda idx: hybrid_recommend(idx, df, embeddings_dict[\"sbert\"], **best_weights_llm_sbert_base),\n",
    "        df=df,\n",
    "        embeddings_for_diversity=embeddings_dict[\"sbert\"],\n",
    "        gt_type=\"llm\",\n",
    "        cache=llm_cache,\n",
    "        min_score=0.5\n",
    "    )\n",
    ")\n",
    "\n",
    "# LLM Oracle\n",
    "results_llm.append(\n",
    "    evaluate_model(\n",
    "        model_name=\"LLM Oracle (Reranked)\",\n",
    "        recommend_fn=lambda idx: llm_rerank_recommend(idx, df, llm_cache, top_k=5),\n",
    "        df=df,\n",
    "        embeddings_for_diversity=embeddings_dict[\"bge\"],\n",
    "        gt_type=\"llm\",\n",
    "        cache=llm_cache,\n",
    "        min_score=0.5\n",
    "    )\n",
    ")\n",
    "\n",
    "print(pd.DataFrame(results_llm).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcadaecd-ce56-491c-a9d7-4d919b3f046e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:30:35.520790Z",
     "iopub.status.busy": "2026-01-16T18:30:35.520517Z",
     "iopub.status.idle": "2026-01-16T18:30:35.529059Z",
     "shell.execute_reply": "2026-01-16T18:30:35.528306Z",
     "shell.execute_reply.started": "2026-01-16T18:30:35.520764Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuning SBERT под LLM-GT\n",
      "Создано 265 обучающих пар.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fine tuning SBERT под LLM-GT\")\n",
    "\n",
    "# Подготовка пар\n",
    "train_pairs = []\n",
    "texts = df[\"content\"].tolist()\n",
    "talk_ids = df[\"talk_id\"].tolist()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    for j in range(i + 1, len(df)):\n",
    "        tid_i, tid_j = talk_ids[i], talk_ids[j]\n",
    "        key = f\"{min(tid_i, tid_j)}_{max(tid_i, tid_j)}\"\n",
    "        llm_score = llm_cache.get(key, 0.0)\n",
    "        if llm_score >= 0.3:\n",
    "            train_pairs.append((texts[i], texts[j], float(llm_score)))\n",
    "\n",
    "print(f\"Создано {len(train_pairs)} обучающих пар.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bce8f7fd-bf82-4383-a1b4-f5d72661d526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:30:35.530292Z",
     "iopub.status.busy": "2026-01-16T18:30:35.529958Z",
     "iopub.status.idle": "2026-01-16T18:30:35.545216Z",
     "shell.execute_reply": "2026-01-16T18:30:35.544673Z",
     "shell.execute_reply.started": "2026-01-16T18:30:35.530268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.pairs[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    a, b, labels = zip(*batch)\n",
    "    labels = torch.tensor(labels, dtype=torch.float)\n",
    "    return list(a), list(b), labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "420dd97d-8594-4e90-89eb-1f82b5a95160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:30:35.546180Z",
     "iopub.status.busy": "2026-01-16T18:30:35.545909Z",
     "iopub.status.idle": "2026-01-16T18:30:37.545900Z",
     "shell.execute_reply": "2026-01-16T18:30:37.545073Z",
     "shell.execute_reply.started": "2026-01-16T18:30:35.546143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58b45424-c7c6-4dc3-8dfc-3782af68110f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:30:37.547282Z",
     "iopub.status.busy": "2026-01-16T18:30:37.546929Z",
     "iopub.status.idle": "2026-01-16T18:30:37.555779Z",
     "shell.execute_reply": "2026-01-16T18:30:37.555246Z",
     "shell.execute_reply.started": "2026-01-16T18:30:37.547248Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    PairDataset(train_pairs),\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0, \n",
    "    generator=g\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.MSELoss()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8330560-388a-4022-998d-0686d1bb375b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:30:37.556938Z",
     "iopub.status.busy": "2026-01-16T18:30:37.556652Z",
     "iopub.status.idle": "2026-01-16T18:31:06.720286Z",
     "shell.execute_reply": "2026-01-16T18:31:06.719553Z",
     "shell.execute_reply.started": "2026-01-16T18:30:37.556903Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe666c3006c4ef599501337db13f0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 0.0532\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c200de0bca0472b87608b073e167eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Avg Loss: 0.0277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45f1bae4c77454cb10f33343125cb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Avg Loss: 0.0196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a02d4d3a7934a68804489ce6d77bd35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Avg Loss: 0.0151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc815ff651c4bd39510574ca716af65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Avg Loss: 0.0119\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    total_loss = 0.0\n",
    "    for texts_a, texts_b, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        optimizer.zero_grad()\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        features_a = model.tokenize(texts_a)\n",
    "        features_b = model.tokenize(texts_b)\n",
    "        for key in features_a:\n",
    "            features_a[key] = features_a[key].to(device)\n",
    "        for key in features_b:\n",
    "            features_b[key] = features_b[key].to(device)\n",
    "        \n",
    "        emb1 = model(features_a)['sentence_embedding']\n",
    "        emb2 = model(features_b)['sentence_embedding']\n",
    "        \n",
    "        emb1 = torch.nn.functional.normalize(emb1, p=2, dim=1)\n",
    "        emb2 = torch.nn.functional.normalize(emb2, p=2, dim=1)\n",
    "        \n",
    "        cos_sim = torch.sum(emb1 * emb2, dim=1)\n",
    "        cos_sim_norm = (cos_sim + 1) / 2\n",
    "        \n",
    "        loss = criterion(cos_sim_norm, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Avg Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0aa1de9d-9fc7-4e29-8e3f-44b94eb4905a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:31:06.721749Z",
     "iopub.status.busy": "2026-01-16T18:31:06.721412Z",
     "iopub.status.idle": "2026-01-16T18:31:06.910895Z",
     "shell.execute_reply": "2026-01-16T18:31:06.910356Z",
     "shell.execute_reply.started": "2026-01-16T18:31:06.721720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Получение эмбеддингов \n",
    "fine_tuned_embs_sbert = model.encode(df[\"content\"].tolist(), convert_to_numpy=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ef28712-8abc-43fc-999c-f5bb3e454a5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:31:06.912042Z",
     "iopub.status.busy": "2026-01-16T18:31:06.911701Z",
     "iopub.status.idle": "2026-01-16T18:31:07.161547Z",
     "shell.execute_reply": "2026-01-16T18:31:07.161048Z",
     "shell.execute_reply.started": "2026-01-16T18:31:06.912004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Оценка fine-tuned SBERT\n",
    "result_finetuned_sbert = evaluate_model(\n",
    "    model_name=\"SBERT (Fine-tuned on LLM-GT)\",\n",
    "    recommend_fn=lambda idx: recommend_by_similarity(idx, fine_tuned_embs_sbert),\n",
    "    df=df,\n",
    "    embeddings_for_diversity=fine_tuned_embs_sbert,\n",
    "    gt_type=\"llm\",\n",
    "    cache=llm_cache,\n",
    "    min_score=0.5\n",
    ")\n",
    "results_llm.append(result_finetuned_sbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "167832e2-0d77-4039-ab39-2534883cafd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:32:26.836985Z",
     "iopub.status.busy": "2026-01-16T18:32:26.836672Z",
     "iopub.status.idle": "2026-01-16T18:34:01.547231Z",
     "shell.execute_reply": "2026-01-16T18:34:01.546538Z",
     "shell.execute_reply.started": "2026-01-16T18:32:26.836958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-16 18:32:26,839]\u001b[0m A new study created in memory with name: no-name-9db19529-87e7-4576-ac30-5bd63d2201da\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимизация гибридной модели на Fine-tuned SBERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-16 18:32:29,921]\u001b[0m Trial 0 finished with value: 0.5545468330383301 and parameters: {'w_sem': 0.6872700594236812, 'w_cat': 0.4753571532049581, 'w_speaker': 0.21959818254342153, 'w_companies': 0.17959754525911098}. Best is trial 0 with value: 0.5545468330383301.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:32:33,044]\u001b[0m Trial 1 finished with value: 0.5485032796859741 and parameters: {'w_sem': 0.5780093202212182, 'w_cat': 0.07799726016810132, 'w_speaker': 0.017425083650459836, 'w_companies': 0.2598528437324805}. Best is trial 0 with value: 0.5545468330383301.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:32:36,195]\u001b[0m Trial 2 finished with value: 0.5569313168525696 and parameters: {'w_sem': 0.8005575058716043, 'w_cat': 0.35403628889802274, 'w_speaker': 0.006175348288740734, 'w_companies': 0.29097295564859826}. Best is trial 2 with value: 0.5569313168525696.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:32:39,245]\u001b[0m Trial 3 finished with value: 0.5773707628250122 and parameters: {'w_sem': 0.9162213204002109, 'w_cat': 0.10616955533913808, 'w_speaker': 0.05454749016213018, 'w_companies': 0.055021352956030146}. Best is trial 3 with value: 0.5773707628250122.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:32:42,312]\u001b[0m Trial 4 finished with value: 0.5521185398101807 and parameters: {'w_sem': 0.6521211214797689, 'w_cat': 0.2623782158161189, 'w_speaker': 0.12958350559263473, 'w_companies': 0.08736874205941257}. Best is trial 3 with value: 0.5773707628250122.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:32:45,283]\u001b[0m Trial 5 finished with value: 0.5559147000312805 and parameters: {'w_sem': 0.8059264473611898, 'w_cat': 0.06974693032602092, 'w_speaker': 0.08764339456056544, 'w_companies': 0.1099085529881075}. Best is trial 3 with value: 0.5773707628250122.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:32:48,294]\u001b[0m Trial 6 finished with value: 0.5606138706207275 and parameters: {'w_sem': 0.728034992108518, 'w_cat': 0.3925879806965068, 'w_speaker': 0.05990213464750792, 'w_companies': 0.15427033152408348}. Best is trial 3 with value: 0.5773707628250122.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:32:51,391]\u001b[0m Trial 7 finished with value: 0.5266556739807129 and parameters: {'w_sem': 0.7962072844310213, 'w_cat': 0.023225206359998862, 'w_speaker': 0.1822634555704315, 'w_companies': 0.051157237106187456}. Best is trial 3 with value: 0.5773707628250122.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:32:54,441]\u001b[0m Trial 8 finished with value: 0.5542891025543213 and parameters: {'w_sem': 0.5325257964926398, 'w_cat': 0.4744427686266666, 'w_speaker': 0.2896896099223678, 'w_companies': 0.24251920443493832}. Best is trial 3 with value: 0.5773707628250122.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:32:57,515]\u001b[0m Trial 9 finished with value: 0.5351752042770386 and parameters: {'w_sem': 0.6523068845866853, 'w_cat': 0.048836057003191935, 'w_speaker': 0.20526990795364705, 'w_companies': 0.13204574812188039}. Best is trial 3 with value: 0.5773707628250122.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:00,626]\u001b[0m Trial 10 finished with value: 0.5869895219802856 and parameters: {'w_sem': 0.9725682721151934, 'w_cat': 0.18186383681081547, 'w_speaker': 0.11061863181632911, 'w_companies': 0.005388562684445819}. Best is trial 10 with value: 0.5869895219802856.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:03,813]\u001b[0m Trial 11 finished with value: 0.5858386754989624 and parameters: {'w_sem': 0.9799381125424057, 'w_cat': 0.17193377205650728, 'w_speaker': 0.10912464381815776, 'w_companies': 0.0036231835506683116}. Best is trial 10 with value: 0.5869895219802856.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:06,746]\u001b[0m Trial 12 finished with value: 0.5869895219802856 and parameters: {'w_sem': 0.9851107053097587, 'w_cat': 0.18337006319079072, 'w_speaker': 0.13212359056252937, 'w_companies': 0.0026058331691794934}. Best is trial 10 with value: 0.5869895219802856.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:09,768]\u001b[0m Trial 13 finished with value: 0.5772263407707214 and parameters: {'w_sem': 0.9106154501066189, 'w_cat': 0.21442697651806494, 'w_speaker': 0.1492423015266554, 'w_companies': 0.0032396635785800283}. Best is trial 10 with value: 0.5869895219802856.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:13,021]\u001b[0m Trial 14 finished with value: 0.5873070955276489 and parameters: {'w_sem': 0.9973847950392343, 'w_cat': 0.2730795500204469, 'w_speaker': 0.16566344209341516, 'w_companies': 0.04322738031647794}. Best is trial 14 with value: 0.5873070955276489.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:16,095]\u001b[0m Trial 15 finished with value: 0.5697543621063232 and parameters: {'w_sem': 0.8957346661249761, 'w_cat': 0.26388944651501595, 'w_speaker': 0.24293279159602826, 'w_companies': 0.060902169589485716}. Best is trial 14 with value: 0.5873070955276489.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:19,348]\u001b[0m Trial 16 finished with value: 0.5763931274414062 and parameters: {'w_sem': 0.9957773943304703, 'w_cat': 0.32471958570209336, 'w_speaker': 0.1755861655648418, 'w_companies': 0.03581287066681278}. Best is trial 14 with value: 0.5873070955276489.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:22,406]\u001b[0m Trial 17 finished with value: 0.601302981376648 and parameters: {'w_sem': 0.8573201599584936, 'w_cat': 0.13704238256391815, 'w_speaker': 0.26151093026265293, 'w_companies': 0.08673747848816071}. Best is trial 17 with value: 0.601302981376648.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:25,411]\u001b[0m Trial 18 finished with value: 0.5795931816101074 and parameters: {'w_sem': 0.8688898137800573, 'w_cat': 0.12077746649016971, 'w_speaker': 0.2986704414939859, 'w_companies': 0.1934021055804256}. Best is trial 17 with value: 0.601302981376648.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:28,433]\u001b[0m Trial 19 finished with value: 0.5771716237068176 and parameters: {'w_sem': 0.8582023123932132, 'w_cat': 0.30747118854271044, 'w_speaker': 0.2564037217467837, 'w_companies': 0.08422769960958637}. Best is trial 17 with value: 0.601302981376648.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:31,389]\u001b[0m Trial 20 finished with value: 0.5779390335083008 and parameters: {'w_sem': 0.9353139471260413, 'w_cat': 0.13979730941687524, 'w_speaker': 0.2558605321482832, 'w_companies': 0.10373041748594974}. Best is trial 17 with value: 0.601302981376648.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:34,487]\u001b[0m Trial 21 finished with value: 0.5815407633781433 and parameters: {'w_sem': 0.9498717728920771, 'w_cat': 0.19743774104229234, 'w_speaker': 0.17386981483981934, 'w_companies': 0.034325528922535514}. Best is trial 17 with value: 0.601302981376648.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:37,423]\u001b[0m Trial 22 finished with value: 0.587761640548706 and parameters: {'w_sem': 0.8546195753801894, 'w_cat': 0.23391465804638678, 'w_speaker': 0.08937234132242415, 'w_companies': 0.03100911358274633}. Best is trial 17 with value: 0.601302981376648.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:40,392]\u001b[0m Trial 23 finished with value: 0.5877242088317871 and parameters: {'w_sem': 0.8352725713024431, 'w_cat': 0.2360771113030698, 'w_speaker': 0.0748066817550472, 'w_companies': 0.07420751716173457}. Best is trial 17 with value: 0.601302981376648.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:43,463]\u001b[0m Trial 24 finished with value: 0.5865062475204468 and parameters: {'w_sem': 0.8393513426573789, 'w_cat': 0.22670922288723505, 'w_speaker': 0.06350658219646695, 'w_companies': 0.1255756558475951}. Best is trial 17 with value: 0.601302981376648.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:46,471]\u001b[0m Trial 25 finished with value: 0.5803587436676025 and parameters: {'w_sem': 0.7578034762167021, 'w_cat': 0.14687063316299026, 'w_speaker': 0.08518827703842471, 'w_companies': 0.07859161295300328}. Best is trial 17 with value: 0.601302981376648.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:49,471]\u001b[0m Trial 26 finished with value: 0.5547723174095154 and parameters: {'w_sem': 0.7525497621402821, 'w_cat': 0.23631225325805016, 'w_speaker': 0.03727458034979171, 'w_companies': 0.15224752924180687}. Best is trial 17 with value: 0.601302981376648.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:52,471]\u001b[0m Trial 27 finished with value: 0.5584712624549866 and parameters: {'w_sem': 0.8255044162944254, 'w_cat': 0.4069968527889158, 'w_speaker': 0.0960089468612346, 'w_companies': 0.07626181710066249}. Best is trial 17 with value: 0.601302981376648.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:55,479]\u001b[0m Trial 28 finished with value: 0.5771018862724304 and parameters: {'w_sem': 0.884855678395729, 'w_cat': 0.31705652176421106, 'w_speaker': 0.03555205525899457, 'w_companies': 0.021911943906381473}. Best is trial 17 with value: 0.601302981376648.\u001b[0m\n",
      "\u001b[32m[I 2026-01-16 18:33:58,416]\u001b[0m Trial 29 finished with value: 0.5523532629013062 and parameters: {'w_sem': 0.7175702601430964, 'w_cat': 0.29575883549786275, 'w_speaker': 0.21607123677711887, 'w_companies': 0.18402218625189568}. Best is trial 17 with value: 0.601302981376648.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"Оптимизация гибридной модели на Fine-tuned SBERT\")\n",
    "best_weights_hybrid_sbert_ft, _ = run_optimization(\n",
    "    df, fine_tuned_embs_sbert, gt_type=\"llm\", cache=llm_cache, n_trials=30, min_score=0.5\n",
    ")\n",
    "\n",
    "result_hybrid_sbert_ft = evaluate_model(\n",
    "    model_name=\"Hybrid (Fine-tuned SBERT + Optuna)\",\n",
    "    recommend_fn=lambda idx: hybrid_recommend(idx, df, fine_tuned_embs_sbert, **best_weights_hybrid_sbert_ft),\n",
    "    df=df,\n",
    "    embeddings_for_diversity=fine_tuned_embs_sbert,\n",
    "    gt_type=\"llm\",\n",
    "    cache=llm_cache,\n",
    "    min_score=0.5\n",
    ")\n",
    "results_llm.append(result_hybrid_sbert_ft)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea905658-1b23-4390-854f-c89de74b8eb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:34:01.548856Z",
     "iopub.status.busy": "2026-01-16T18:34:01.548538Z",
     "iopub.status.idle": "2026-01-16T18:34:01.556179Z",
     "shell.execute_reply": "2026-01-16T18:34:01.555355Z",
     "shell.execute_reply.started": "2026-01-16T18:34:01.548830Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальное сравнение всех моделей(по LLM-GT)\n",
      "                             Model  Recall@5 (LLM-GT)  Diversity  Composite\n",
      "                            TF-IDF              0.208      0.958      0.433\n",
      "                          Word2Vec              0.048      0.108      0.066\n",
      "                     Sentence-BERT              0.256      0.511      0.333\n",
      "                            BGE-M3              0.281      0.459      0.335\n",
      "                              BM25              0.109      0.960      0.365\n",
      "             Hybrid (BGE + Optuna)              0.361      0.469      0.394\n",
      "           Hybrid (SBERT + Optuna)              0.329      0.533      0.390\n",
      "             LLM Oracle (Reranked)              1.000      0.499      0.850\n",
      "      SBERT (Fine-tuned on LLM-GT)              0.373      0.846      0.515\n",
      "Hybrid (Fine-tuned SBERT + Optuna)              0.459      0.886      0.587\n",
      "Hybrid (Fine-tuned SBERT + Optuna)              0.487      0.867      0.601\n"
     ]
    }
   ],
   "source": [
    "print(\"Финальное сравнение всех моделей(по LLM-GT)\")\n",
    "\n",
    "final_results_df = pd.DataFrame(results_llm)\n",
    "print(final_results_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9259420,
     "sourceId": 14496952,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9260874,
     "sourceId": 14499077,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9261460,
     "sourceId": 14499977,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
